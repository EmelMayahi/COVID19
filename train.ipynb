{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%run '/content/drive/MyDrive/Master_Machine_Learning/COVID19/models.ipynb'"
      ],
      "metadata": {
        "id": "GEVisjQuHayx"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "import torch\n",
        "import time\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "# from models import resnet50\t#\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from PIL import ImageFile\n",
        "from sklearn.metrics import f1_score,precision_score,recall_score,roc_auc_score,accuracy_score"
      ],
      "metadata": {
        "id": "yBpcO2qOyNFR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "import torch\n",
        "import time\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "#from models import resnet50\t#\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from PIL import ImageFile\n",
        "from sklearn.metrics import f1_score,precision_score,recall_score,roc_auc_score,accuracy_score\n",
        "\n",
        "def main():\n",
        "    ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "    # os.environ['CUDA_VISIBLE_DEVICES'] = '0,3'\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"using {} device.\".format(device))\n",
        "\n",
        "    # 定义画图函数\n",
        "    def matplot_loss(train_loss, val_loss,save_path):\n",
        "        plt.plot(train_loss, label='train_loss')\n",
        "        plt.plot(val_loss, label='val_loss')\n",
        "        plt.legend(loc='best')\n",
        "        plt.ylabel('loss-acc')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.title(\"Accuracy-Loss\")\n",
        "\n",
        "        plt.savefig(save_path+'/'+'Loss.pdf',dpi=500,format='pdf')\n",
        "        plt.savefig(save_path+'/'+'Loss.svg',dpi=500,bbox_inches = 'tight')\n",
        "        plt.show()\n",
        "    def matplot_acc(train_acc, val_acc,save_path):\n",
        "        plt.plot(train_acc, label='train_acc')\n",
        "        plt.plot(val_acc, label='val_acc')\n",
        "        plt.legend(loc='best')\n",
        "        plt.ylabel('loss-acc')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.title(\"Accuracy-Loss\")\n",
        "\n",
        "        plt.savefig(save_path+'/'+'Accuracy.pdf',dpi=500,format='pdf')\n",
        "        plt.savefig(save_path+'/'+'Accuracy.svg',dpi=500,bbox_inches = 'tight')\n",
        "        plt.show()\n",
        "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    #normalize = transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    data_transform = {\n",
        "        \"train\": transforms.Compose([transforms.RandomResizedCrop(224),\n",
        "                                     transforms.RandomHorizontalFlip(),\n",
        "                                     transforms.ToTensor(),\n",
        "                                     normalize,\n",
        "                                     ]),\n",
        "        \"val\": transforms.Compose([transforms.Resize(256),\n",
        "                                   transforms.CenterCrop(224),\n",
        "                                   transforms.ToTensor(),\n",
        "                                   normalize\n",
        "                                   ])}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    train_data = r'/content/drive/MyDrive/Dataset/covid/train'\n",
        "    val_data = r'/content/drive/MyDrive/Dataset/covid/val'\n",
        "\n",
        "\n",
        "    train_dataset = datasets.ImageFolder(train_data,\n",
        "                                         transform=data_transform[\"train\"])\n",
        "\n",
        "    train_num = len(train_dataset)\n",
        "\n",
        "\n",
        "    classes_list = train_dataset.class_to_idx\n",
        "    cla_dict = dict((val, key) for key, val in classes_list.items())\n",
        "    # write dict into json file\n",
        "    json_str = json.dumps(cla_dict, indent=4)\n",
        "    with open('class_indicesskin.json', 'w') as json_file:\n",
        "        json_file.write(json_str)\n",
        "\n",
        "    batch_size = 32\n",
        "    nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 16])  # number of workers\n",
        "    print('Using {} dataloader workers every process'.format(nw))\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                               batch_size=batch_size, shuffle=True,\n",
        "                                               num_workers=nw)\n",
        "\n",
        "    validate_dataset = datasets.ImageFolder(val_data,\n",
        "                                            transform=data_transform[\"val\"])\n",
        "    val_num = len(validate_dataset)\n",
        "    validate_loader = torch.utils.data.DataLoader(validate_dataset,\n",
        "                                                  batch_size=batch_size, shuffle=True,\n",
        "                                                  num_workers=nw)\n",
        "\n",
        "    print(\"using {} images for training, {} images for validation.\".format(train_num,\n",
        "                                                                           val_num))\n",
        "\n",
        "    net = resnet50(num_classes=2)\n",
        "    # pre_weights=torch.load(\"/home/lsw/projecet/utils/resnet50-19c8e357.pth\")\n",
        "    # pre_dict = {k: v for k, v in pre_weights.items() if net.state_dict()[k].numel() == v.numel()}\n",
        "    # missing_keys, unexpected_keys = net.load_state_dict(pre_dict, strict=False)\n",
        "\n",
        "    # change fc layer structure\n",
        "    # if torch.cuda.device_count() > 1:\n",
        "    #     net = nn.DataParallel(net)\n",
        "    net.to(device)\n",
        "\n",
        "    # define loss function\n",
        "    # weight = torch.FloatTensor([6., 1., 13., 21., 6., 58., 47.])\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "    # loss_function = nn.CrossEntropyLoss(weight=torch.from_numpy(np.array([0.44,0.73,0.83])).float(),reduction='mean')\n",
        "\n",
        "    # loss_function.to(device)\n",
        "\n",
        "\n",
        "    # construct an optimizer\n",
        "    params = [p for p in net.parameters() if p.requires_grad]\n",
        "    optimizer = optim.Adam(params, lr=0.0001)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
        "    epochs = 300\n",
        "    train_best_acc = 0.0\n",
        "    val_best_acc = 0.0\n",
        "\n",
        "    train_steps = len(train_loader)\n",
        "    val_steps = len(validate_loader)\n",
        "    loss_train = []\n",
        "    acc_train = []\n",
        "    loss_val = []\n",
        "    acc_val = []\n",
        "    for epoch in range(epochs):\n",
        "        # train\n",
        "        net.train()\n",
        "        acc0 = 0.0\n",
        "        running_loss = 0.0\n",
        "        predlist=[]\n",
        "        scorelist=[]\n",
        "        targetlist=[]\n",
        "        train_bar = tqdm(train_loader)\n",
        "        for step, data in enumerate(train_bar):\n",
        "            images, labels = data\n",
        "            optimizer.zero_grad()\n",
        "            logits = net(images.to(device))\n",
        "\n",
        "            loss = loss_function(logits, labels.to(device))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            predict_y0 = torch.max(logits, dim=1)[1]\n",
        "            acc0 += torch.eq(predict_y0, labels.to(device)).sum().item()\n",
        "            train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch + 1,epochs,loss)\n",
        "\n",
        "        train_loss = running_loss / train_steps\n",
        "        train_accurate = acc0 / train_num\n",
        "\n",
        "        # validate\n",
        "        net.eval()\n",
        "\n",
        "        \"\"\"acc = 0.0  # accumulate accurate number / epoch\n",
        "        valdata_loss = 0.0\n",
        "        time1 = \"%s\"%datetime.now()\n",
        "        labels = [0,1]\n",
        "        #labels = [0,1,2,3,4,5,6]\n",
        "        with torch.no_grad():\n",
        "            val_bar = tqdm(validate_loader)\n",
        "            for val_data in val_bar:\n",
        "                val_images, val_labels = val_data\n",
        "\n",
        "                outputs = net(val_images.to(device))\n",
        "                # print(outputs)\n",
        "\n",
        "                predict_y = torch.max(outputs, dim=1)[1]\n",
        "                # print(predict_y,val_labels)\n",
        "                # exit()\n",
        "                acc += torch.eq(predict_y, val_labels.to(device)).sum().item()\n",
        "                valloss = loss_function(outputs, val_labels.to(device))\n",
        "                valdata_loss += valloss.item()\n",
        "                val_bar.desc = \"valid epoch[{}/{}]\".format(epoch + 1,epochs)\n",
        "                predlist=np.append(predlist, predict_y.cpu().numpy())\n",
        "                targetlist=np.append(targetlist,val_labels)\n",
        "        val_loss = valdata_loss / val_steps\n",
        "        val_accurate = acc / val_num\n",
        "\n",
        "        #用于绘图\n",
        "        loss_train.append(train_loss)\n",
        "        acc_train.append(train_accurate)\n",
        "        loss_val.append(val_loss)\n",
        "        acc_val.append(val_accurate)\n",
        "        train_val_folder = r'/code/new/model_train_val/covid'\n",
        "        if not os.path.exists(train_val_folder):\n",
        "            os.mkdir(train_val_folder)\n",
        "        list = [time1,epoch,train_loss,train_accurate,val_loss,val_accurate]\n",
        "        data = pd.DataFrame([list])\n",
        "        data.to_csv(train_val_folder+'/'+'train_log.csv',mode='w',header=False,index=False)\n",
        "        output = \"%s：Step [%d],  train_loss : %f, train_accuracy :  %g,val_loss : %f, val_accuracy :  %g\" % (datetime.now(),epoch, train_loss, train_accurate,val_loss,val_accurate)\n",
        "        with open(train_val_folder+'/'+'train_log.txt',\"a+\") as f:\n",
        "            f.write(output+'\\n')\n",
        "            f.close\n",
        "        with open(train_val_folder+'/'+'draw_lists.txt',\"w\") as f:\n",
        "            f.write('{:}\\n {:}\\n {:}\\n {:}\\n '.format(loss_train,acc_train,loss_val,acc_val))\n",
        "            f.close\n",
        "\n",
        "        print('[epoch %d] train_loss: %.3f train_acc: %.3f val_loss: %.3f val_acc: %.3f ' %\n",
        "              (epoch + 1, running_loss / train_steps,train_accurate,val_loss ,val_accurate))\n",
        "\n",
        "        model_folder = r'/code/new/save_model/covid'\n",
        "        if not os.path.exists(model_folder):\n",
        "            os.mkdir(model_folder)\n",
        "        save_path0 = model_folder+'/train.pth'\n",
        "        save_path1 = model_folder+'/val.pth'\n",
        "        if train_accurate > train_best_acc:\n",
        "            train_best_acc = train_accurate\n",
        "            torch.save(net.state_dict(),save_path0)\n",
        "        if val_accurate > val_best_acc:\n",
        "            val_best_acc = val_accurate\n",
        "            torch.save(net.state_dict(),save_path1)\n",
        "            train_val_folder = r'/code/new/model_train_val/covid'\n",
        "            if not os.path.exists(train_val_folder):\n",
        "                os.mkdir(train_val_folder)\n",
        "            with open(train_val_folder+'/targetlist.txt','a+') as f:\n",
        "                for tar in targetlist:\n",
        "                    f.write(str(tar)+'\\n')\n",
        "                    f.close\n",
        "            with open(train_val_folder+'/predlist.txt','a+') as f:\n",
        "                for pre in predlist:\n",
        "                    f.write(str(pre)+'\\n')\n",
        "                    f.close \"\"\"\n",
        "\n",
        "        acc = accuracy_score(targetlist, predlist, normalize=True)\n",
        "        F1 = f1_score(targetlist, predlist, average='macro')\n",
        "        precision = precision_score(targetlist, predlist,  labels=None, pos_label=1, average='macro')\n",
        "        recall = recall_score(targetlist, predlist,  labels=None,average='macro', sample_weight=None)\n",
        "        val_lab = label_binarize(targetlist, classes=labels)\n",
        "        val_pre = label_binarize(predlist, classes=labels)\n",
        "        auc = roc_auc_score(val_lab, val_pre, average='macro')\n",
        "        print('acc',acc)\n",
        "        print('F1',F1)\n",
        "        print('precision',precision)\n",
        "        print('recall',recall)\n",
        "        print('auc',auc)\n",
        "        print('best_acc',val_best_acc)\n",
        "        with open(train_val_folder+'/metrics.txt','a+') as f:\n",
        "            f.write('acc:{}, F1:{}, precision:{}, recall:{}, auc:{}\\n'.format(acc,F1,precision,recall,auc))\n",
        "            f.close\n",
        "    output_folder = r'/code/new/output/covid'\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.mkdir(output_folder)\n",
        "\n",
        "    matplot_loss(loss_train, loss_val,output_folder)\n",
        "    matplot_acc(acc_train, acc_val,output_folder)\n",
        "    print('Finished Training')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3Deea9OPQpUc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    np.random.seed(0)\n",
        "    torch.manual_seed(0)\n",
        "    torch.cuda.manual_seed_all(0)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    main()"
      ],
      "metadata": {
        "id": "tSOkicP8Uios",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eec0d72-519c-4290-b5ff-8c7076ff7e37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cpu device.\n",
            "Using 2 dataloader workers every process\n",
            "using 35 images for training, 15 images for validation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        }
      ]
    }
  ]
}